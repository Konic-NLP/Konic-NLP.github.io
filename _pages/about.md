---
permalink: /
title: "About me([Curriculum Vitae](https://Konic-NLP.github.io/files/Sijia%20Ge-CV.pdf))"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---  
  
&nbsp;

A self-driven explorer for NLP and related skills with strong passion for ML/DL, software development. I immerse myself into the challenging journey with thorns to enrich my CS skills since I am not a CS guy originally. I love fantastic techniques which bring me the instant feedback and the sense of accomplishment.

Now I am a student of [Computational Linguistics, Analytics, Search and Informatics Professional Master’s Degree (CLASIC) program](https://www.colorado.edu/linguistics/graduate-program/computational-linguistics-clasic-ms) at [The University of Colorado-Boulder](https://www.colorado.edu/).  Such an interdisciplinary degree is offered jointly by The [Departments of Linguistics](https://www.colorado.edu/linguistics/) and [Computer Science](https://www.colorado.edu/cs/).I got B.A. degree in the department of Chinese language and literature of Shanxi University (Major in Chinese language and literature) and M.A. degree in Nanjing Normal University(Major in Linguistics and Applied linguistics). 

I have 4 years+ Python experience and 2 years+ NLP research experience. My past work focused on lexcial analysis (i.e token classification/sequence labeling tasks like named entity recognition and word segementation, etc); corpus construction(high quality annotation for text dataset, especially for semantic role labeling, like [Chinese Abstract Meaning Representation corpus](https://www.cs.brandeis.edu/~clp/camr/camr.html) and Chinese FrameNet), and digital huminities(I explore how to structually represent the meaning of literature like ancient Chinese poems as much as possible).
  
  
Before entering the CU-Boulder, I worked as a product manager intern in Beijing Lingosail company(China), designed and upgraded the product ['Termbox'](http://termbox.lingosail.com/) for term extraction.


**My major technical stacks**:  
- Programming languages: Python/Java
- ML/DL: Keras, sklearn, tensorflow
- Web development: Django


**License**

- Structured Query Language from Coursera [view](https://github.com/Konic-NLP/Konic-NLP.github.io/blob/master/files/Coursera%20Q7MAJJK9F576.pdf)

- Programming Language -Python from China Mocc [view](https://github.com/Konic-NLP/Konic-NLP.github.io/blob/master/files/%E8%AF%81%E4%B9%A6.png)


Selected Publication
=======
## paper

Ning Cheng, Bin Li, Liming Xiao, Changwei Xu, **Sijia Ge**, Xingyue Hao, Minxuan Feng. Integration of Automatic Sentence Segmentation and Lexical Analysis of Ancient Chinese based on BiLSTM-CRF Model. *Proceedings of LT4HALA 2020 - 1st Workshop on Language Technologies for Historical and Ancient Languages*. Marseille, France,2020:52-58. [pdf](https://aclanthology.org/2020.lt4hala-1.8.pdf) 

*****  

Xingyue Hao, **Sijia Ge***, Yang Zhang, Yuling Dai, Peiyi Yan, and Bin Li. The Construction and Analysis of Annotated Imagery Corpus of Three Hundred Tang Poems. *J.-F. Hong et al. (Eds.): Proceedings of the 20th Chinese Lexical Semantics Workshop (CLSW 2019)*, LNAI 11831, pp. 517–524, 2020.   [pdf](https://link.springer.com/content/pdf/10.1007%2F978-3-030-38189-9_53.pdf)
  
******  
Li  Song, Yuan  Wen,  **Sijia  Ge**,  Bin  Li,  Junsheng  Zhou,  Weiguang  Qu  and  Nianwen  Xue. An  Easier  and  Efficient Framework to Annotate Semantic Roles: Evidence from the Chinese AMR Corpus.*The 13th Workshop on Asian Language Resources on LREC 2018*. Miyazaki, Japan, May 07, 2018:29-35.   [pdf](http://lrec-conf.org/workshops/lrec2018/W29/pdf/15_W29.pdf)
  
  
## patent 
A  Method  and  System  of  Automatic  Lexical  Analysis  for  Ancient  Chinese.  (the  3 rd   applicant).2019. No.CN201910085019.3 


<br>Code projects on Github
=======
## Natural Language Processing 

- Text classification with XLNET, logistic regression, BI-LSTM/SVM with embeddings. The data including a hotel reviews and SemEval shared task 4 for 'Don't Petronize Me' detection. The implementation with pytorch, keras, tensorflow, sklearn.
[repo](https://github.com/Konic-NLP/text-classification)


- Name Entity Recognition with token-based tagging(BIO/BIOE)
  - NER with BERT, which loaded the pre-trained model from huggingface[repo](https://github.com/Konic-NLP/BERT-NER/blob/main/copy_of_ner_bert.py)
  - BI-LSTM implementation with tensorflow, can choose BI-LSTM or IDCNN as the model architecture, IDCNN is faster. [repo](https://github.com/Konic-NLP/NER/blob/main/NER-BERT.py)
  - CRF++(C++ source)/CRFsuite implementation, the feature template can be edited by the users. [repo](https://github.com/Konic-NLP/NER) 

***********

## Computer Vision

- MNIST recognition with scikit-learn [code](https://github.com/Konic-NLP/5922-deep-learning/blob/main/lab_assignment1_.ipynb)
- Cifar-10 image classification with Keras(using regularization L2/Batch Normilization/Drop out) [code](https://github.com/Konic-NLP/5922-deep-learning/blob/main/lab_assignment2.ipynb)
- Viz-Wiz challenge: VQA for blind people, extracting questions and image features via BERT and VGG-16, then feed the flatten feature vector into a MLP. [code](https://github.com/Konic-NLP/5922-deep-learning/blob/main/lab_assignment4.ipynb)

**************

## Software Development and Object-Oriented Design

- A music store simulation, including the functionality like placing an order, checking the inventory, sell the items, buying items and so on. Injecting design patterns into the code, including factory, strategy, decorator, command, observer, singleton. Design with class UML, state diagram and sequence diagram. The language we use Java.[repo](https://github.com/Konic-NLP/OOAD-project)

- A online e-commerce shopping website development. Implementing with Django 2,  we use JS and Jquery for front end and Django-admin for backstage management.[repo](https://github.com/Konic-NLP/final-project-OOAD)


****************

## Coding Practice 

- Python Data sturcture and Algorithms.[repo](https://github.com/Konic-NLP/Data_sturcture_algorithms)  [![update](https://img.shields.io/badge/last%20updated-June%202022-lightgrey) "including my handwriting notes in Chinese"]

- Java Learning with UCB CS 61B. [repo](https://github.com/Konic-NLP/Java-learning)
- Machine Learning(implemented with *Machine Learning in Action*).[repo](https://github.com/Konic-NLP/Machine_Learning) 




<!-- A data-driven personal website
======
Like many other Jekyll-based GitHub Pages templates, academicpages makes you separate the website's content from its form. The content & metadata of your website are in structured markdown files, while various other files constitute the theme, specifying how to transform that content & metadata into HTML pages. You keep these various markdown (.md), YAML (.yml), HTML, and CSS files in a public GitHub repository. Each time you commit and push an update to the repository, the [GitHub pages](https://pages.github.com/) service creates static HTML pages based on these files, which are hosted on GitHub's servers free of charge.

Many of the features of dynamic content management systems (like Wordpress) can be achieved in this fashion, using a fraction of the computational resources and with far less vulnerability to hacking and DDoSing. You can also modify the theme to your heart's content without touching the content of your site. If you get to a point where you've broken something in Jekyll/HTML/CSS beyond repair, your markdown files describing your talks, publications, etc. are safe. You can rollback the changes or even delete the repository and start over -- just be sure to save the markdown files! Finally, you can also write scripts that process the structured data on the site, such as [this one](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.ipynb) that analyzes metadata in pages about talks to display [a map of every location you've given a talk](https://academicpages.github.io/talkmap.html). -->
